{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13857827,"sourceType":"datasetVersion","datasetId":8828018}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:12.048107Z","iopub.execute_input":"2025-11-30T20:30:12.048263Z","iopub.status.idle":"2025-11-30T20:30:13.754614Z","shell.execute_reply.started":"2025-11-30T20:30:12.048248Z","shell.execute_reply":"2025-11-30T20:30:13.753930Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/all-dataset/politifact_real.csv\n/kaggle/input/all-dataset/politifact_fake.csv\n/kaggle/input/all-dataset/gossipcop_real.csv\n/kaggle/input/all-dataset/gossipcop_fake.csv\n/kaggle/input/all-dataset/liar_dataset/test.tsv\n/kaggle/input/all-dataset/liar_dataset/README\n/kaggle/input/all-dataset/liar_dataset/train.tsv\n/kaggle/input/all-dataset/liar_dataset/valid.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\n\ntry:\n    import transformers\nexcept ImportError:\n    import subprocess, sys\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\", \"accelerate\", \"datasets\"])\n    import transformers\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Setup complete\")\nprint(f\"PyTorch version     : {torch.__version__}\")\nprint(f\"Transformers version: {transformers.__version__}\")\nprint(f\"Using device        : {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:13.756018Z","iopub.execute_input":"2025-11-30T20:30:13.756387Z","iopub.status.idle":"2025-11-30T20:30:24.537455Z","shell.execute_reply.started":"2025-11-30T20:30:13.756368Z","shell.execute_reply":"2025-11-30T20:30:24.536729Z"}},"outputs":[{"name":"stdout","text":"Setup complete\nPyTorch version     : 2.6.0+cu124\nTransformers version: 4.53.3\nUsing device        : cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\nprint(\"Folders in /kaggle/input/:\")\nprint(os.listdir(\"/kaggle/input/\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:24.538134Z","iopub.execute_input":"2025-11-30T20:30:24.538539Z","iopub.status.idle":"2025-11-30T20:30:24.543205Z","shell.execute_reply.started":"2025-11-30T20:30:24.538517Z","shell.execute_reply":"2025-11-30T20:30:24.542521Z"}},"outputs":[{"name":"stdout","text":"Folders in /kaggle/input/:\n['all-dataset']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\nfolder = \"/kaggle/input/all-dataset\"\n\nprint(\"Files inside all-dataset:\")\nprint(os.listdir(folder))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:24.544000Z","iopub.execute_input":"2025-11-30T20:30:24.544306Z","iopub.status.idle":"2025-11-30T20:30:24.564624Z","shell.execute_reply.started":"2025-11-30T20:30:24.544264Z","shell.execute_reply":"2025-11-30T20:30:24.563976Z"}},"outputs":[{"name":"stdout","text":"Files inside all-dataset:\n['politifact_real.csv', 'politifact_fake.csv', 'liar_dataset', 'gossipcop_real.csv', 'gossipcop_fake.csv']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\nliar_folder = \"/kaggle/input/all-dataset/liar_dataset\"\n\nprint(\"Files inside liar_dataset:\")\nprint(os.listdir(liar_folder))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:24.565287Z","iopub.execute_input":"2025-11-30T20:30:24.565516Z","iopub.status.idle":"2025-11-30T20:30:24.576953Z","shell.execute_reply.started":"2025-11-30T20:30:24.565500Z","shell.execute_reply":"2025-11-30T20:30:24.576296Z"}},"outputs":[{"name":"stdout","text":"Files inside liar_dataset:\n['test.tsv', 'README', 'train.tsv', 'valid.tsv']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# Step 3: Loading LIAR + FakeNewsNet \n\n\nimport pandas as pd\nimport os\n\nbase_path = \"/kaggle/input/all-dataset\"\n\n\n# 1. Load LIAR dataset\n\nliar_folder = os.path.join(base_path, \"liar_dataset\")\n\ntrain_path = os.path.join(liar_folder, \"train.tsv\")\nval_path   = os.path.join(liar_folder, \"valid.tsv\")  \ntest_path  = os.path.join(liar_folder, \"test.tsv\")\n\ntrain_df = pd.read_csv(train_path, sep=\"\\t\", header=None, quoting=3, on_bad_lines='skip')\nval_df   = pd.read_csv(val_path,   sep=\"\\t\", header=None, quoting=3, on_bad_lines='skip')\ntest_df  = pd.read_csv(test_path,  sep=\"\\t\", header=None, quoting=3, on_bad_lines='skip')\n\nprint(\"LIAR Dataset Loaded!\")\nprint(\"Train:\", train_df.shape)\nprint(\"Val  :\", val_df.shape)\nprint(\"Test :\", test_df.shape)\n\n\n# 2. Loading FakeNewsNet datasets\n\ngossip_fake = pd.read_csv(os.path.join(base_path, \"gossipcop_fake.csv\"))\ngossip_real = pd.read_csv(os.path.join(base_path, \"gossipcop_real.csv\"))\n\npolitifact_fake = pd.read_csv(os.path.join(base_path, \"politifact_fake.csv\"))\npolitifact_real = pd.read_csv(os.path.join(base_path, \"politifact_real.csv\"))\n\nprint(\"\\nFakeNewsNet Loaded!\")\nprint(\"Gossip Fake:\", gossip_fake.shape)\nprint(\"Gossip Real:\", gossip_real.shape)\nprint(\"Politi Fake:\", politifact_fake.shape)\nprint(\"Politi Real:\", politifact_real.shape)\n\nprint(\"\\nSample LIAR train row:\")\ndisplay(train_df.head())\n\nprint(\"\\nSample GossipCop Fake row:\")\ndisplay(gossip_fake.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:24.577783Z","iopub.execute_input":"2025-11-30T20:30:24.577989Z","iopub.status.idle":"2025-11-30T20:30:25.683906Z","shell.execute_reply.started":"2025-11-30T20:30:24.577974Z","shell.execute_reply":"2025-11-30T20:30:25.683190Z"}},"outputs":[{"name":"stdout","text":"LIAR Dataset Loaded!\nTrain: (10269, 14)\nVal  : (1284, 14)\nTest : (1283, 14)\n\nFakeNewsNet Loaded!\nGossip Fake: (5323, 4)\nGossip Real: (16817, 4)\nPoliti Fake: (432, 4)\nPoliti Real: (624, 4)\n\nSample LIAR train row:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           0            1                                                  2   \\\n0   2635.json        false  Says the Annies List political group supports ...   \n1  10540.json    half-true  When did the decline of coal start? It started...   \n2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n3   1123.json        false  Health care reform legislation is likely to ma...   \n4   9028.json    half-true  The economic turnaround started at the end of ...   \n\n                                   3               4                     5   \\\n0                            abortion    dwayne-bohac  State representative   \n1  energy,history,job-accomplishments  scott-surovell        State delegate   \n2                      foreign-policy    barack-obama             President   \n3                         health-care    blog-posting                   NaN   \n4                        economy,jobs   charlie-crist                   NaN   \n\n         6           7   8   9    10   11  12                   13  \n0     Texas  republican   0   1    0    0   0             a mailer  \n1  Virginia    democrat   0   0    1    1   0      a floor speech.  \n2  Illinois    democrat  70  71  160  163   9               Denver  \n3       NaN        none   7  19    3    5  44       a news release  \n4   Florida    democrat  15   9   20   19   2  an interview on CNN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2635.json</td>\n      <td>false</td>\n      <td>Says the Annies List political group supports ...</td>\n      <td>abortion</td>\n      <td>dwayne-bohac</td>\n      <td>State representative</td>\n      <td>Texas</td>\n      <td>republican</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>a mailer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10540.json</td>\n      <td>half-true</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>a floor speech.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.json</td>\n      <td>mostly-true</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70</td>\n      <td>71</td>\n      <td>160</td>\n      <td>163</td>\n      <td>9</td>\n      <td>Denver</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1123.json</td>\n      <td>false</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7</td>\n      <td>19</td>\n      <td>3</td>\n      <td>5</td>\n      <td>44</td>\n      <td>a news release</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9028.json</td>\n      <td>half-true</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15</td>\n      <td>9</td>\n      <td>20</td>\n      <td>19</td>\n      <td>2</td>\n      <td>an interview on CNN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nSample GossipCop Fake row:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                     id                                           news_url  \\\n0  gossipcop-2493749932  www.dailymail.co.uk/tvshowbiz/article-5874213/...   \n1  gossipcop-4580247171  hollywoodlife.com/2018/05/05/paris-jackson-car...   \n2   gossipcop-941805037  variety.com/2017/biz/news/tax-march-donald-tru...   \n3  gossipcop-2547891536  www.dailymail.co.uk/femail/article-3499192/Do-...   \n4  gossipcop-5476631226  variety.com/2018/film/news/list-2018-oscar-nom...   \n\n                                               title  \\\n0  Did Miley Cyrus and Liam Hemsworth secretly ge...   \n1  Paris Jackson & Cara Delevingne Enjoy Night Ou...   \n2  Celebrities Join Tax March in Protest of Donal...   \n3  Cindy Crawford's daughter Kaia Gerber wears a ...   \n4      Full List of 2018 Oscar Nominations – Variety   \n\n                                           tweet_ids  \n0  284329075902926848\\t284332744559968256\\t284335...  \n1  992895508267130880\\t992897935418503169\\t992899...  \n2  853359353532829696\\t853359576543920128\\t853359...  \n3  988821905196158981\\t988824206556172288\\t988825...  \n4  955792793632432131\\t955795063925301249\\t955798...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gossipcop-2493749932</td>\n      <td>www.dailymail.co.uk/tvshowbiz/article-5874213/...</td>\n      <td>Did Miley Cyrus and Liam Hemsworth secretly ge...</td>\n      <td>284329075902926848\\t284332744559968256\\t284335...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gossipcop-4580247171</td>\n      <td>hollywoodlife.com/2018/05/05/paris-jackson-car...</td>\n      <td>Paris Jackson &amp; Cara Delevingne Enjoy Night Ou...</td>\n      <td>992895508267130880\\t992897935418503169\\t992899...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gossipcop-941805037</td>\n      <td>variety.com/2017/biz/news/tax-march-donald-tru...</td>\n      <td>Celebrities Join Tax March in Protest of Donal...</td>\n      <td>853359353532829696\\t853359576543920128\\t853359...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gossipcop-2547891536</td>\n      <td>www.dailymail.co.uk/femail/article-3499192/Do-...</td>\n      <td>Cindy Crawford's daughter Kaia Gerber wears a ...</td>\n      <td>988821905196158981\\t988824206556172288\\t988825...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gossipcop-5476631226</td>\n      <td>variety.com/2018/film/news/list-2018-oscar-nom...</td>\n      <td>Full List of 2018 Oscar Nominations – Variety</td>\n      <td>955792793632432131\\t955795063925301249\\t955798...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"\n#Prepare LIAR columns and labels\n\n\n# Assigning column names based on LIAR documentation\nliar_columns = [\n    \"id\",\n    \"label\",\n    \"statement\",\n    \"subject\",\n    \"speaker\",\n    \"speaker_job\",\n    \"state\",\n    \"party\",\n    \"barely_true_counts\",\n    \"false_counts\",\n    \"half_true_counts\",\n    \"mostly_true_counts\",\n    \"pants_on_fire_counts\",\n    \"context\",\n]\n\ntrain_df.columns = liar_columns\nval_df.columns   = liar_columns\ntest_df.columns  = liar_columns\n\nprint(\"Column names assigned.\")\nprint(\"Train columns:\", train_df.columns.tolist())\n\n# 2. Createating a clean text column (we will use this for the model)\nfor df_name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n    df[\"text\"] = df[\"statement\"].astype(str)\n\n# 3. Inspecting label values\nprint(\"\\nUnique labels in LIAR:\")\nprint(train_df[\"label\"].unique())\n\nprint(\"\\nLabel distribution (train):\")\nprint(train_df[\"label\"].value_counts())\n\n# 4. Map string labels → numeric IDs (needed for modeling)\n# We'll keep all 6 veracity classes:\n# 'pants-fire', 'false', 'barely-true', 'half-true', 'mostly-true', 'true'\n\nunique_labels = sorted(train_df[\"label\"].unique())\nlabel_to_id = {lab: idx for idx, lab in enumerate(unique_labels)}\nid_to_label = {idx: lab for lab, idx in label_to_id.items()}\n\nprint(\"\\nLabel → ID mapping:\")\nfor lab, idx in label_to_id.items():\n    print(f\"{lab:12s} -> {idx}\")\n\ntrain_df[\"label_id\"] = train_df[\"label\"].map(label_to_id)\nval_df[\"label_id\"]   = val_df[\"label\"].map(label_to_id)\n\nprint(\"\\n Added 'text' and 'label_id' columns to train/val.\")\nprint(train_df[[\"text\", \"label\", \"label_id\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:25.685864Z","iopub.execute_input":"2025-11-30T20:30:25.686080Z","iopub.status.idle":"2025-11-30T20:30:25.713026Z","shell.execute_reply.started":"2025-11-30T20:30:25.686063Z","shell.execute_reply":"2025-11-30T20:30:25.712448Z"}},"outputs":[{"name":"stdout","text":"Column names assigned.\nTrain columns: ['id', 'label', 'statement', 'subject', 'speaker', 'speaker_job', 'state', 'party', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n\nUnique labels in LIAR:\n['false' 'half-true' 'mostly-true' 'true' 'barely-true' 'pants-fire']\n\nLabel distribution (train):\nlabel\nhalf-true      2123\nfalse          1998\nmostly-true    1966\ntrue           1683\nbarely-true    1657\npants-fire      842\nName: count, dtype: int64\n\nLabel → ID mapping:\nbarely-true  -> 0\nfalse        -> 1\nhalf-true    -> 2\nmostly-true  -> 3\npants-fire   -> 4\ntrue         -> 5\n\n Added 'text' and 'label_id' columns to train/val.\n                                                text        label  label_id\n0  Says the Annies List political group supports ...        false         1\n1  When did the decline of coal start? It started...    half-true         2\n2  Hillary Clinton agrees with John McCain \"by vo...  mostly-true         3\n3  Health care reform legislation is likely to ma...        false         1\n4  The economic turnaround started at the end of ...    half-true         2\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n# Step 5 : Tokenizer + Dataset + Loaders\n\n\nimport torch\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset, DataLoader\n\n# 1. Choosing model tokenizer\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nprint(\"Loaded tokenizer:\", model_name)\n\n# 2. PyTorch Dataset\nclass LiarDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length=128):\n        self.texts = df[\"text\"].tolist()\n        self.labels = df[\"label_id\"].tolist()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = int(self.labels[idx])\n\n        enc = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n\n        # remove extra batch dim → (seq_len) instead of (1, seq_len)\n        item = {key: val.squeeze(0) for key, val in enc.items()}\n        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n\n        return item\n\n# 3. Build datasets\nmax_length = 128\ntrain_dataset = LiarDataset(train_df, tokenizer, max_length=max_length)\nval_dataset   = LiarDataset(val_df, tokenizer, max_length=max_length)\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Val dataset size  : {len(val_dataset)}\")\n\n# 4. DataLoaders\nbatch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n# 5. Inspect sample batch\nbatch = next(iter(train_loader))\n\nprint(\"\\nBatch keys:\", batch.keys())\nprint(\"input_ids shape:\", batch[\"input_ids\"].shape)\nprint(\"attention_mask shape:\", batch[\"attention_mask\"].shape)\nprint(\"labels shape:\", batch[\"labels\"].shape)\n\nprint(\"\\n Dataloaders are ready.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:25.713702Z","iopub.execute_input":"2025-11-30T20:30:25.714042Z","iopub.status.idle":"2025-11-30T20:30:26.924024Z","shell.execute_reply.started":"2025-11-30T20:30:25.714022Z","shell.execute_reply":"2025-11-30T20:30:26.923224Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe813742bf034119904d2b440b4e087b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56e99bf6c79c401587344a53ea502cab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1458acadfe440ba5edc3a5dae551aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d73dae7a47d499d8c8983e35893e08a"}},"metadata":{}},{"name":"stdout","text":"Loaded tokenizer: distilbert-base-uncased\nTrain dataset size: 10269\nVal dataset size  : 1284\n\nBatch keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\ninput_ids shape: torch.Size([16, 128])\nattention_mask shape: torch.Size([16, 128])\nlabels shape: torch.Size([16])\n\n Dataloaders are ready.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\n# Step 6A: taking Small subset for fast training\n\n\nimport torch\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Small subset so we don't wait forever\ntrain_small_df = train_df.sample(2000, random_state=42)  # 2k rows\nval_small_df   = val_df.sample(500,  random_state=42)    # 500 rows\n\ntrain_small_dataset = LiarDataset(train_small_df, tokenizer, max_length=128)\nval_small_dataset   = LiarDataset(val_small_df, tokenizer, max_length=128)\n\ntrain_small_loader = DataLoader(train_small_dataset, batch_size=16, shuffle=True)\nval_small_loader   = DataLoader(val_small_dataset, batch_size=16, shuffle=False)\n\nprint(f\"Small train size: {len(train_small_dataset)}\")\nprint(f\"Small val size  : {len(val_small_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:26.924950Z","iopub.execute_input":"2025-11-30T20:30:26.925233Z","iopub.status.idle":"2025-11-30T20:30:26.934374Z","shell.execute_reply.started":"2025-11-30T20:30:26.925215Z","shell.execute_reply":"2025-11-30T20:30:26.933791Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nSmall train size: 2000\nSmall val size  : 500\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n# Step 6B: Manual training loop (1 epoch)\n\n\nfrom transformers import AutoModelForSequenceClassification\nfrom torch.optim import AdamW\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport torch\n\nnum_labels = len(label_to_id)\n\n# 1. Load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=num_labels\n).to(device)\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\nmodel.train()\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n    epoch_loss = 0.0\n    step = 0\n\n    for batch in tqdm(train_small_loader):\n        # Move batch to GPU/CPU\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        step += 1\n\n        if step % 20 == 0:\n            print(f\"Step {step} - Avg loss so far: {epoch_loss / step:.4f}\")\n\n    print(f\"Epoch {epoch+1} finished. Avg loss: {epoch_loss / step:.4f}\")\n\n# Evaluation on small val set \nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(val_small_loader):\n        labels = batch[\"labels\"].numpy()\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        logits = outputs.logits.detach().cpu().numpy()\n        preds = logits.argmax(axis=1)\n\n        all_preds.append(preds)\n        all_labels.append(labels)\n\nall_preds = np.concatenate(all_preds)\nall_labels = np.concatenate(all_labels)\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"\\nValidation accuracy (small subset): {acc:.4f}\\n\")\n\nprint(\"Classification report (small subset):\")\nprint(classification_report(\n    all_labels,\n    all_preds,\n    target_names=[id_to_label[i] for i in range(len(id_to_label))]\n))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:30:26.935054Z","iopub.execute_input":"2025-11-30T20:30:26.935330Z","iopub.status.idle":"2025-11-30T20:31:13.745620Z","shell.execute_reply.started":"2025-11-30T20:30:26.935308Z","shell.execute_reply":"2025-11-30T20:31:13.744833Z"}},"outputs":[{"name":"stderr","text":"2025-11-30 20:30:30.328088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764534630.511198      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764534630.566673      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec3e3f0571d455284e9edd14da1baad"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n===== Epoch 1/1 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba85bedcbe9848c59ec776f22a25571d"}},"metadata":{}},{"name":"stdout","text":"Step 20 - Avg loss so far: 1.7848\nStep 40 - Avg loss so far: 1.7774\nStep 60 - Avg loss so far: 1.7711\nStep 80 - Avg loss so far: 1.7622\nStep 100 - Avg loss so far: 1.7553\nStep 120 - Avg loss so far: 1.7515\nEpoch 1 finished. Avg loss: 1.7526\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5ac206cd7c64dafb7c603d1876948b6"}},"metadata":{}},{"name":"stdout","text":"\nValidation accuracy (small subset): 0.2320\n\nClassification report (small subset):\n              precision    recall  f1-score   support\n\n barely-true       0.00      0.00      0.00        95\n       false       0.28      0.36      0.32       108\n   half-true       0.20      0.51      0.28       105\n mostly-true       0.26      0.24      0.25        96\n  pants-fire       0.00      0.00      0.00        41\n        true       0.00      0.00      0.00        55\n\n    accuracy                           0.23       500\n   macro avg       0.12      0.19      0.14       500\nweighted avg       0.15      0.23      0.18       500\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\n# Step 7A: Full train/val dataloaders\n\n\nfrom torch.utils.data import DataLoader\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n\nfull_train_dataset = LiarDataset(train_df, tokenizer, max_length=128)\nfull_val_dataset   = LiarDataset(val_df,   tokenizer, max_length=128)\n\nbatch_size = 16\n\nfull_train_loader = DataLoader(full_train_dataset, batch_size=batch_size, shuffle=True)\nfull_val_loader   = DataLoader(full_val_dataset,   batch_size=batch_size, shuffle=False)\n\nprint(f\"Full train size: {len(full_train_dataset)}\")\nprint(f\"Full val size  : {len(full_val_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:31:13.746348Z","iopub.execute_input":"2025-11-30T20:31:13.746900Z","iopub.status.idle":"2025-11-30T20:31:13.753908Z","shell.execute_reply.started":"2025-11-30T20:31:13.746880Z","shell.execute_reply":"2025-11-30T20:31:13.753335Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nFull train size: 10269\nFull val size  : 1284\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Step 7B: Full LIAR training + evaluation\n\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification\nfrom torch.optim import AdamW\nfrom tqdm.auto import tqdm\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nnum_labels = len(label_to_id)\n\n# 1. Loading  a fresh model for full training\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=num_labels\n).to(device)\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\nnum_epochs = 2\n\nfor epoch in range(num_epochs):\n    print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n    model.train()\n    epoch_loss = 0.0\n    step = 0\n\n    for batch in tqdm(full_train_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        step += 1\n\n        # print running avg loss occasionally\n        if step % 100 == 0:\n            print(f\"Step {step} - Avg loss so far: {epoch_loss / step:.4f}\")\n\n    print(f\"Epoch {epoch+1} finished. Avg train loss: {epoch_loss / step:.4f}\")\n\n    # Validation after each epoch \n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(full_val_loader):\n            labels = batch[\"labels\"].numpy()\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            outputs = model(**batch)\n            logits = outputs.logits.detach().cpu().numpy()\n            preds = logits.argmax(axis=1)\n\n            all_preds.append(preds)\n            all_labels.append(labels)\n\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"\\n[Epoch {epoch+1}] Validation accuracy: {acc:.4f}\")\n\n    print(\"Classification report:\")\n    print(classification_report(\n        all_labels,\n        all_preds,\n        target_names=[id_to_label[i] for i in range(len(id_to_label))]\n    ))\n\nprint(\"\\n Full LIAR training + evaluation complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:31:13.754601Z","iopub.execute_input":"2025-11-30T20:31:13.754843Z","iopub.status.idle":"2025-11-30T20:35:16.244491Z","shell.execute_reply.started":"2025-11-30T20:31:13.754817Z","shell.execute_reply":"2025-11-30T20:35:16.243844Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n\n===== Epoch 1/2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c96db96567e94d77b89d2bdc43e390e1"}},"metadata":{}},{"name":"stdout","text":"Step 100 - Avg loss so far: 1.7684\nStep 200 - Avg loss so far: 1.7567\nStep 300 - Avg loss so far: 1.7464\nStep 400 - Avg loss so far: 1.7355\nStep 500 - Avg loss so far: 1.7309\nStep 600 - Avg loss so far: 1.7220\nEpoch 1 finished. Avg train loss: 1.7208\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/81 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97738580b064dcfbb413e53c5e3e97d"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch 1] Validation accuracy: 0.2609\nClassification report:\n              precision    recall  f1-score   support\n\n barely-true       0.29      0.01      0.02       237\n       false       0.28      0.40      0.33       263\n   half-true       0.22      0.43      0.29       248\n mostly-true       0.29      0.41      0.34       251\n  pants-fire       0.00      0.00      0.00       116\n        true       0.25      0.11      0.16       169\n\n    accuracy                           0.26      1284\n   macro avg       0.22      0.23      0.19      1284\nweighted avg       0.24      0.26      0.21      1284\n\n\n===== Epoch 2/2 =====\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/642 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1da1a2fece3549ef8e78ad3e96199661"}},"metadata":{}},{"name":"stdout","text":"Step 100 - Avg loss so far: 1.6171\nStep 200 - Avg loss so far: 1.6283\nStep 300 - Avg loss so far: 1.6220\nStep 400 - Avg loss so far: 1.6254\nStep 500 - Avg loss so far: 1.6210\nStep 600 - Avg loss so far: 1.6181\nEpoch 2 finished. Avg train loss: 1.6184\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/81 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25227a1147c64d61ad355d2033e1b57b"}},"metadata":{}},{"name":"stdout","text":"\n[Epoch 2] Validation accuracy: 0.2710\nClassification report:\n              precision    recall  f1-score   support\n\n barely-true       0.25      0.34      0.29       237\n       false       0.29      0.28      0.28       263\n   half-true       0.26      0.21      0.23       248\n mostly-true       0.31      0.22      0.25       251\n  pants-fire       0.34      0.29      0.31       116\n        true       0.23      0.32      0.27       169\n\n    accuracy                           0.27      1284\n   macro avg       0.28      0.28      0.27      1284\nweighted avg       0.28      0.27      0.27      1284\n\n\n Full LIAR training + evaluation complete.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# FakeNewsNet - Cell 1: Load + Clean + Merge\n\n\nimport re\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nprint(\"Merging FakeNewsNet datasets...\")\n\ndef clean_text(text):\n    text = str(text)\n    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)  \n    text = re.sub(r\"<.*?>\", \" \", text)            \n    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)   \n    text = re.sub(r\"\\s+\", \" \", text)              \n    return text.strip().lower()\n\n\n\n\ngossip_fake[\"label\"] = 1\ngossip_real[\"label\"] = 0\npolitifact_fake[\"label\"] = 1\npolitifact_real[\"label\"] = 0\n\n\nTEXT_COL = \"text\"  # change if needed\n\nif TEXT_COL not in gossip_fake.columns:\n    TEXT_COL = gossip_fake.columns[0]  # fallback\n\n# Merge\nfakenews_df = pd.concat([\n    gossip_fake[[TEXT_COL, \"label\"]],\n    gossip_real[[TEXT_COL, \"label\"]],\n    politifact_fake[[TEXT_COL, \"label\"]],\n    politifact_real[[TEXT_COL, \"label\"]],\n], ignore_index=True)\n\n# Clean text\nfakenews_df[\"text\"] = fakenews_df[TEXT_COL].astype(str).apply(clean_text)\n\n# Convert label\nfakenews_df[\"label_id\"] = fakenews_df[\"label\"].astype(int)\n\nprint(\"Label counts:\\n\", fakenews_df[\"label_id\"].value_counts())\n\n# Split\ntrain_fakenet, val_fakenet = train_test_split(\n    fakenews_df,\n    test_size=0.2,\n    random_state=42,\n    stratify=fakenews_df[\"label_id\"]\n)\n\nprint(\"\\nTrain size:\", len(train_fakenet))\nprint(\"Val size  :\", len(val_fakenet))\n\nprint(\"\\nSample rows:\")\ndisplay(train_fakenet.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:35:16.245310Z","iopub.execute_input":"2025-11-30T20:35:16.245539Z","iopub.status.idle":"2025-11-30T20:35:16.374237Z","shell.execute_reply.started":"2025-11-30T20:35:16.245522Z","shell.execute_reply":"2025-11-30T20:35:16.373648Z"}},"outputs":[{"name":"stdout","text":"Merging FakeNewsNet datasets...\nLabel counts:\n label_id\n0    17441\n1     5755\nName: count, dtype: int64\n\nTrain size: 18556\nVal size  : 4640\n\nSample rows:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                         id  label                  text  label_id\n4756   gossipcop-9800162301      1  gossipcop 9800162301         1\n18824      gossipcop-857120      0      gossipcop 857120         0\n3242   gossipcop-6176274941      1  gossipcop 6176274941         1\n5435       gossipcop-944376      0      gossipcop 944376         0\n21562      gossipcop-946635      0      gossipcop 946635         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>text</th>\n      <th>label_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4756</th>\n      <td>gossipcop-9800162301</td>\n      <td>1</td>\n      <td>gossipcop 9800162301</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18824</th>\n      <td>gossipcop-857120</td>\n      <td>0</td>\n      <td>gossipcop 857120</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3242</th>\n      <td>gossipcop-6176274941</td>\n      <td>1</td>\n      <td>gossipcop 6176274941</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5435</th>\n      <td>gossipcop-944376</td>\n      <td>0</td>\n      <td>gossipcop 944376</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21562</th>\n      <td>gossipcop-946635</td>\n      <td>0</td>\n      <td>gossipcop 946635</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"\n# FakeNewsNet - Cell 2: Dataset + DataLoaders\n\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nclass FakeNewsTextDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length=256):\n        self.texts = df[\"text\"].tolist()\n        self.labels = df[\"label_id\"].tolist()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = int(self.labels[idx])\n\n        enc = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n        item = {k: v.squeeze(0) for k, v in enc.items()}\n        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n        return item\n\nmax_length_fakenet = 256\n\ntrain_fakenet_ds = FakeNewsTextDataset(train_fakenet, tokenizer, max_length=max_length_fakenet)\nval_fakenet_ds   = FakeNewsTextDataset(val_fakenet,   tokenizer, max_length=max_length_fakenet)\n\ntrain_fakenet_loader = DataLoader(train_fakenet_ds, batch_size=16, shuffle=True)\nval_fakenet_loader   = DataLoader(val_fakenet_ds,   batch_size=16, shuffle=False)\n\nprint(\"Train loader batches:\", len(train_fakenet_loader))\nprint(\"Val loader batches  :\", len(val_fakenet_loader))\n\n# Peek at one batch\nbatch = next(iter(train_fakenet_loader))\nprint(\"\\nBatch keys:\", batch.keys())\nprint(\"input_ids shape:\", batch[\"input_ids\"].shape)\nprint(\"labels shape   :\", batch[\"labels\"].shape)\n\nprint(\"\\n FakeNewsNet DataLoaders ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:35:16.375061Z","iopub.execute_input":"2025-11-30T20:35:16.375663Z","iopub.status.idle":"2025-11-30T20:35:16.393757Z","shell.execute_reply.started":"2025-11-30T20:35:16.375633Z","shell.execute_reply":"2025-11-30T20:35:16.392978Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTrain loader batches: 1160\nVal loader batches  : 290\n\nBatch keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\ninput_ids shape: torch.Size([16, 256])\nlabels shape   : torch.Size([16])\n\n FakeNewsNet DataLoaders ready.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# FakeNewsNet - Cell 3: Training DistilBERT\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification\nfrom torch.optim import AdamW\nfrom tqdm.auto import tqdm\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Binary classifier → 2 labels\nmodel_fakenet = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=2\n).to(device)\n\noptimizer = AdamW(model_fakenet.parameters(), lr=2e-5)\ncriterion = torch.nn.CrossEntropyLoss()\n\nnum_epochs_fakenet = 2  # 2 epochs is usually enough for FakeNewsNet\n\nfor epoch in range(num_epochs_fakenet):\n    print(f\"\\n===== FakeNewsNet Epoch {epoch+1}/{num_epochs_fakenet} =====\")\n    model_fakenet.train()\n    epoch_loss = 0.0\n    step = 0\n\n    for batch in tqdm(train_fakenet_loader):\n        labels = batch[\"labels\"].to(device)\n        batch_inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n\n        outputs = model_fakenet(**batch_inputs)\n        logits = outputs.logits\n        loss = criterion(logits, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        step += 1\n\n        if step % 100 == 0:\n            print(f\"Step {step} - Avg loss: {epoch_loss / step:.4f}\")\n\n    print(f\"\\nEpoch {epoch+1} finished. Avg train loss: {epoch_loss / step:.4f}\")\n\n    #Validation\n    model_fakenet.eval()\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in val_fakenet_loader:\n            labels = batch[\"labels\"].numpy()\n            batch_inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n\n            outputs = model_fakenet(**batch_inputs)\n            logits = outputs.logits.detach().cpu().numpy()\n            preds = logits.argmax(axis=1)\n\n            all_preds.append(preds)\n            all_labels.append(labels)\n\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"\\n[FakeNewsNet Epoch {epoch+1}] Validation Accuracy: {acc:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=[\"real\", \"fake\"]))\n\nprint(\"\\n FakeNewsNet text model training complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:35:16.394611Z","iopub.execute_input":"2025-11-30T20:35:16.394816Z","iopub.status.idle":"2025-11-30T20:50:00.070957Z","shell.execute_reply.started":"2025-11-30T20:35:16.394801Z","shell.execute_reply":"2025-11-30T20:50:00.070340Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n===== FakeNewsNet Epoch 1/2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c5360f998be43c48d9f5aeb49db2cc3"}},"metadata":{}},{"name":"stdout","text":"Step 100 - Avg loss: 0.1787\nStep 200 - Avg loss: 0.1027\nStep 300 - Avg loss: 0.0777\nStep 400 - Avg loss: 0.0617\nStep 500 - Avg loss: 0.0519\nStep 600 - Avg loss: 0.0470\nStep 700 - Avg loss: 0.0414\nStep 800 - Avg loss: 0.0389\nStep 900 - Avg loss: 0.0355\nStep 1000 - Avg loss: 0.0329\nStep 1100 - Avg loss: 0.0334\n\nEpoch 1 finished. Avg train loss: 0.0325\n\n[FakeNewsNet Epoch 1] Validation Accuracy: 0.9972\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        real       1.00      1.00      1.00      3489\n        fake       0.99      1.00      0.99      1151\n\n    accuracy                           1.00      4640\n   macro avg       0.99      1.00      1.00      4640\nweighted avg       1.00      1.00      1.00      4640\n\n\n===== FakeNewsNet Epoch 2/2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d621a44690de4cbabbf3cc46863bcf04"}},"metadata":{}},{"name":"stdout","text":"Step 100 - Avg loss: 0.0078\nStep 200 - Avg loss: 0.0108\nStep 300 - Avg loss: 0.0095\nStep 400 - Avg loss: 0.0093\nStep 500 - Avg loss: 0.0091\nStep 600 - Avg loss: 0.0091\nStep 700 - Avg loss: 0.0095\nStep 800 - Avg loss: 0.0097\nStep 900 - Avg loss: 0.0097\nStep 1000 - Avg loss: 0.0094\nStep 1100 - Avg loss: 0.0099\n\nEpoch 2 finished. Avg train loss: 0.0100\n\n[FakeNewsNet Epoch 2] Validation Accuracy: 0.9972\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        real       1.00      1.00      1.00      3489\n        fake       1.00      0.99      0.99      1151\n\n    accuracy                           1.00      4640\n   macro avg       1.00      1.00      1.00      4640\nweighted avg       1.00      1.00      1.00      4640\n\n\n FakeNewsNet text model training complete.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Propagation - Cell 4: Download graph dataset\n\n\nimport os, subprocess, sys\n\nrepo_url = \"https://github.com/mdepak/fake-news-propagation.git\"\nrepo_dir = \"/kaggle/working/fake-news-propagation\"\n\n# 1) Clone the repo if not already present\nif not os.path.exists(repo_dir):\n    print(\"Cloning propagation dataset repo...\")\n    try:\n        subprocess.check_call([\"git\", \"clone\", repo_url, repo_dir])\n        print(\" Cloned repository.\")\n    except Exception as e:\n        print(\" Error cloning repository.\")\n        print(e)\nelse:\n    print(\"Repo already exists at\", repo_dir)\n\n# 2) Unzip nx_network_data.zip if present\nzip_path = os.path.join(repo_dir, \"data\", \"nx_network_data.zip\")\ndata_dir = os.path.join(repo_dir, \"data\")\n\nif os.path.exists(zip_path):\n    print(\"\\nUnzipping nx_network_data.zip ...\")\n    try:\n        import zipfile\n        with zipfile.ZipFile(zip_path, \"r\") as z:\n            z.extractall(data_dir)\n        print(\" Unzipped into:\", data_dir)\n    except Exception as e:\n        print(\" Error unzipping nx_network_data.zip\")\n        print(e)\nelse:\n    print(\"\\n nx_network_data.zip not found at:\", zip_path)\n    print(\"   Check the repo structure or download manually.\")\n\n# 3) List what’s inside data/\nif os.path.exists(data_dir):\n    print(\"\\nContents of data directory:\")\n    print(os.listdir(data_dir))\nelse:\n    print(\"\\nData directory not found:\", data_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:50:00.071689Z","iopub.execute_input":"2025-11-30T20:50:00.071949Z","iopub.status.idle":"2025-11-30T20:50:05.550189Z","shell.execute_reply.started":"2025-11-30T20:50:00.071931Z","shell.execute_reply":"2025-11-30T20:50:05.549579Z"}},"outputs":[{"name":"stdout","text":"Cloning propagation dataset repo...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/fake-news-propagation'...\n","output_type":"stream"},{"name":"stdout","text":" Cloned repository.\n\nUnzipping nx_network_data.zip ...\n Unzipped into: /kaggle/working/fake-news-propagation/data\n\nContents of data directory:\n['sample_ids', 'nx_network_data.zip', '__MACOSX', 'nx_network_data']\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Propagation - Install DGL (GPU)\n\n\nprint(\"Installing DGL for CUDA...\")\n\n!pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html\n\nprint(\"\\n DGL installation complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:50:05.550841Z","iopub.execute_input":"2025-11-30T20:50:05.551023Z","iopub.status.idle":"2025-11-30T20:52:10.502628Z","shell.execute_reply.started":"2025-11-30T20:50:05.551009Z","shell.execute_reply":"2025-11-30T20:52:10.501690Z"}},"outputs":[{"name":"stdout","text":"Installing DGL for CUDA...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Looking in links: https://data.dgl.ai/wheels/cu118/repo.html\nCollecting dgl\n  Downloading https://data.dgl.ai/wheels/cu118/dgl-2.1.0%2Bcu118-cp311-cp311-manylinux1_x86_64.whl (748.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.2/748.2 MB\u001b[0m \u001b[31m952.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.26.4)\nRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.15.3)\nRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.5)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (7.1.3)\nRequirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (0.11.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.10.5)\nRequirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata>=0.5.0->dgl) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.15.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->dgl) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->dgl) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->dgl) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->dgl) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->dgl) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->dgl) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.3)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dgl-2.1.0+cu118 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n\n DGL installation complete!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Propagation - Cell 5: Load + Convert graphs\n\n\nimport os\nimport json\nimport networkx as nx\nimport dgl\nimport torch\n\nGRAPH_PATH = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\ngraph_files = sorted(os.listdir(GRAPH_PATH))\n\nprint(\"Total graph files found:\", len(graph_files))\nprint(\"Example graph file:\", graph_files[0])\n\nsample_graph_file = os.path.join(GRAPH_PATH, graph_files[0])\nprint(\"\\nLoading:\", sample_graph_file)\n\nwith open(sample_graph_file, \"r\") as f:\n    graph_json = json.load(f)\n\nnx_graph = nx.node_link_graph(graph_json)\n\nprint(\"NetworkX graph loaded.\")\nprint(\"Nodes:\", nx_graph.number_of_nodes())\nprint(\"Edges:\", nx_graph.number_of_edges())\n\ndgl_graph = dgl.from_networkx(nx_graph)\n\nnum_nodes = dgl_graph.num_nodes()\ndgl_graph.ndata[\"feat\"] = torch.eye(num_nodes)\n\nprint(\"\\nDGL graph created:\")\nprint(\"Nodes:\", dgl_graph.num_nodes())\nprint(\"Edges:\", dgl_graph.num_edges())\nprint(\"Node feature shape:\", dgl_graph.ndata[\"feat\"].shape)\n\nprint(\"\\n Graph conversion successful!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:52:10.503798Z","iopub.execute_input":"2025-11-30T20:52:10.504386Z","iopub.status.idle":"2025-11-30T20:52:10.908186Z","shell.execute_reply.started":"2025-11-30T20:52:10.504362Z","shell.execute_reply":"2025-11-30T20:52:10.906886Z"}},"outputs":[{"name":"stdout","text":"Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","output_type":"stream"},{"name":"stderr","text":"DGL backend not selected or invalid.  Assuming PyTorch for now.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1101126656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Backend and logging should be imported before other modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menable_verbose_logging\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_backend\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m from . import (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mload_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_preferred_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36mload_backend\u001b[0;34m(mod_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported backend: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_tensor_adapter\u001b[0m  \u001b[0;31m# imports DGL C library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/_ffi/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# library instance of nnvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0m_LIB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_LIB_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DIR_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# The FFI mode of DGL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/_ffi/base.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m\"\"\"Load libary by searching possible path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlib_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_lib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mbasename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: libcudart.so.11.0: cannot open shared object file: No such file or directory"],"ename":"OSError","evalue":"libcudart.so.11.0: cannot open shared object file: No such file or directory","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"# Propagation - Fix DGL install (CPU version)\n\n\nprint(\"Uninstalling existing DGL (if any)...\")\n!pip uninstall -y dgl\n\nprint(\"\\nInstalling CPU-only DGL...\")\n!pip install dgl==1.1.2 -f https://data.dgl.ai/wheels/repo.html\n\nprint(\"\\n DGL CPU installation complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:56:21.111925Z","iopub.execute_input":"2025-11-30T20:56:21.112718Z","iopub.status.idle":"2025-11-30T20:56:27.199604Z","shell.execute_reply.started":"2025-11-30T20:56:21.112689Z","shell.execute_reply":"2025-11-30T20:56:27.198817Z"}},"outputs":[{"name":"stdout","text":"Uninstalling existing DGL (if any)...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Found existing installation: dgl 2.1.0+cu118\nUninstalling dgl-2.1.0+cu118:\n  Successfully uninstalled dgl-2.1.0+cu118\n\nInstalling CPU-only DGL...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Looking in links: https://data.dgl.ai/wheels/repo.html\nCollecting dgl==1.1.2\n  Downloading dgl-1.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (530 bytes)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (1.26.4)\nRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (1.15.3)\nRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (3.5)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (4.67.1)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (7.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl==1.1.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl==1.1.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl==1.1.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl==1.1.2) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl==1.1.2) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->dgl==1.1.2) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->dgl==1.1.2) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->dgl==1.1.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->dgl==1.1.2) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->dgl==1.1.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->dgl==1.1.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->dgl==1.1.2) (2024.2.0)\nDownloading dgl-1.1.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: dgl\nSuccessfully installed dgl-1.1.2\n\n DGL CPU installation complete. Now re-run the graph code.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Propagation - Cell 5 (retry): Load + Convert\n\n\nimport os\nimport json\nimport networkx as nx\nimport dgl\nimport torch\n\nGRAPH_PATH = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\ngraph_files = sorted(os.listdir(GRAPH_PATH))\n\nprint(\"Total graph files found:\", len(graph_files))\nprint(\"Example graph file:\", graph_files[0])\n\nsample_graph_file = os.path.join(GRAPH_PATH, graph_files[0])\nprint(\"\\nLoading:\", sample_graph_file)\n\nwith open(sample_graph_file, \"r\") as f:\n    graph_json = json.load(f)\n\nnx_graph = nx.node_link_graph(graph_json)\n\nprint(\"NetworkX graph loaded.\")\nprint(\"Nodes:\", nx_graph.number_of_nodes())\nprint(\"Edges:\", nx_graph.number_of_edges())\n\ndgl_graph = dgl.from_networkx(nx_graph)\n\nnum_nodes = dgl_graph.num_nodes()\ndgl_graph.ndata[\"feat\"] = torch.eye(num_nodes)\n\nprint(\"\\nDGL graph created:\")\nprint(\"Nodes:\", dgl_graph.num_nodes())\nprint(\"Edges:\", dgl_graph.num_edges())\nprint(\"Node feature shape:\", dgl_graph.ndata[\"feat\"].shape)\n\nprint(\"\\n Graph conversion successful!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:56:31.336205Z","iopub.execute_input":"2025-11-30T20:56:31.336963Z","iopub.status.idle":"2025-11-30T20:56:31.523596Z","shell.execute_reply.started":"2025-11-30T20:56:31.336936Z","shell.execute_reply":"2025-11-30T20:56:31.522641Z"}},"outputs":[{"name":"stdout","text":"Total graph files found: 4\nExample graph file: gossipcop_fake\n\nLoading: /kaggle/working/fake-news-propagation/data/nx_network_data/gossipcop_fake\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2962698519.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nLoading:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_graph_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_graph_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mgraph_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/working/fake-news-propagation/data/nx_network_data/gossipcop_fake'"],"ename":"IsADirectoryError","evalue":"[Errno 21] Is a directory: '/kaggle/working/fake-news-propagation/data/nx_network_data/gossipcop_fake'","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"# Propagation - Cell 5D: Inspect folder structure\n\nimport os\n\nGRAPH_ROOT = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\nprint(\"Root contents:\", os.listdir(GRAPH_ROOT))\n\n# For each category, list its first few files\nfor folder in os.listdir(GRAPH_ROOT):\n    folder_path = os.path.join(GRAPH_ROOT, folder)\n    if os.path.isdir(folder_path):\n        print(f\"\\n {folder} contains {len(os.listdir(folder_path))} graph files\")\n        print(\"First 5:\", os.listdir(folder_path)[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:57:23.779100Z","iopub.execute_input":"2025-11-30T20:57:23.779395Z","iopub.status.idle":"2025-11-30T20:57:23.796305Z","shell.execute_reply.started":"2025-11-30T20:57:23.779375Z","shell.execute_reply":"2025-11-30T20:57:23.795595Z"}},"outputs":[{"name":"stdout","text":"Root contents: ['gossipcop_real', 'politifact_real', 'politifact_fake', 'gossipcop_fake']\n\n gossipcop_real contains 6945 graph files\nFirst 5: ['gossipcop-817047.json', 'gossipcop-849450.json', 'gossipcop-955278.json', 'gossipcop-878459.json', 'gossipcop-862744.json']\n\n politifact_real contains 277 graph files\nFirst 5: ['politifact1519.json', 'politifact11761.json', 'politifact440.json', 'politifact8310.json', 'politifact1053.json']\n\n politifact_fake contains 351 graph files\nFirst 5: ['politifact15383.json', 'politifact14644.json', 'politifact13816.json', 'politifact14755.json', 'politifact13973.json']\n\n gossipcop_fake contains 3684 graph files\nFirst 5: ['gossipcop-328760913.json', 'gossipcop-4131669926.json', 'gossipcop-3484539870.json', 'gossipcop-2022735106.json', 'gossipcop-5237284121.json']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"\n# Propagation - Cell 5E: Load 1 graph → DGL\n\n\nimport os\nimport json\nimport networkx as nx\nimport dgl\nimport torch\n\nGRAPH_ROOT = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\n# 1. Choose a category and pick one file\ncategory = \"gossipcop_fake\"  # you can change to gossipcop_real / politifact_fake / politifact_real\nfolder_path = os.path.join(GRAPH_ROOT, category)\n\nfiles_in_folder = sorted(os.listdir(folder_path))\nprint(f\"Category: {category}, files: {len(files_in_folder)}\")\n\nsample_file = files_in_folder[0]\nfile_path = os.path.join(folder_path, sample_file)\n\nprint(\"Loading graph file:\", file_path)\n\n# 2. Load JSON → NetworkX\nwith open(file_path, \"r\") as f:\n    graph_json = json.load(f)\n\nnx_graph = nx.node_link_graph(graph_json)\n\nprint(\"NetworkX graph loaded.\")\nprint(\"Nodes:\", nx_graph.number_of_nodes())\nprint(\"Edges:\", nx_graph.number_of_edges())\n\n# 3. NetworkX → DGL\ndgl_graph = dgl.from_networkx(nx_graph)\n\nprint(\"\\nDGL graph created.\")\nprint(\"Nodes:\", dgl_graph.num_nodes())\nprint(\"Edges:\", dgl_graph.num_edges())\n\n# 4. Add simple node features: in-degree as a scalar feature\ndeg = dgl_graph.in_degrees().float().unsqueeze(1)  # shape [N, 1]\ndgl_graph.ndata[\"feat\"] = deg\n\nprint(\"Node feature shape:\", dgl_graph.ndata[\"feat\"].shape)\n\nprint(\"\\n Single propagation graph conversion successful!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:57:28.342949Z","iopub.execute_input":"2025-11-30T20:57:28.343668Z","iopub.status.idle":"2025-11-30T20:57:28.389125Z","shell.execute_reply.started":"2025-11-30T20:57:28.343641Z","shell.execute_reply":"2025-11-30T20:57:28.387922Z"}},"outputs":[{"name":"stdout","text":"Category: gossipcop_fake, files: 3684\nLoading graph file: /kaggle/working/fake-news-propagation/data/nx_network_data/gossipcop_fake/gossipcop-1000240645.json\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/networkx/readwrite/json_graph/node_link.py:290: FutureWarning: \nThe default value will be changed to `edges=\"edges\" in NetworkX 3.6.\n\nTo make this warning go away, explicitly set the edges kwarg, e.g.:\n\n  nx.node_link_graph(data, edges=\"links\") to preserve current behavior, or\n  nx.node_link_graph(data, edges=\"edges\") for forward compatibility.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/647121071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgraph_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_link_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NetworkX graph loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# standard function-wrapping stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_node_link_graph_1\u001b[0;34m(data, directed, multigraph, source, target, name, key, edges, nodes, link, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m_call_if_any_backends_installed\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph_backend_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgraph_backend_names\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_backend_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 elif self._can_convert(\n\u001b[1;32m    931\u001b[0m                     \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_backend_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m_call_with_backend\u001b[0;34m(self, backend_name, args, kwargs, extra_message)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[0;34m\"\"\"Call this dispatchable function with a backend without converting inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"networkx\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1463\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1464\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         _logger.debug(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/readwrite/json_graph/node_link.py\u001b[0m in \u001b[0;36mnode_link_graph\u001b[0;34m(data, directed, multigraph, source, target, name, key, edges, nodes, link)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mnodedata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'nodes'"],"ename":"KeyError","evalue":"'nodes'","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"# Show contents of one JSON graph file\n\n\nimport os\n\nGRAPH_ROOT = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\n# pick a folder\nfolder = \"gossipcop_fake\"\nfolder_path = os.path.join(GRAPH_ROOT, folder)\n\n# pick a JSON file inside the folder\nfiles = sorted(os.listdir(folder_path))\njson_file = files[0]  # first file\njson_path = os.path.join(folder_path, json_file)\n\nprint(\"Showing file:\", json_path, \"\\n\")\n\n# print the first 400 characters\nwith open(json_path, \"r\") as f:\n    content = f.read()\n\nprint(content[:400])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:57:45.543060Z","iopub.execute_input":"2025-11-30T20:57:45.543358Z","iopub.status.idle":"2025-11-30T20:57:45.551950Z","shell.execute_reply.started":"2025-11-30T20:57:45.543338Z","shell.execute_reply":"2025-11-30T20:57:45.551401Z"}},"outputs":[{"name":"stdout","text":"Showing file: /kaggle/working/fake-news-propagation/data/nx_network_data/gossipcop_fake/gossipcop-1000240645.json \n\n{\"time\": null, \"type\": 1, \"user\": 3849187751, \"tweet_id\": \"gossipcop-1000240645\", \"id\": 9303106605, \"children\": [{\"time\": 1250565338, \"type\": 2, \"user\": 4472255223, \"tweet_id\": 3375455802, \"id\": 7822188508}, {\"time\": 1259094442, \"type\": 2, \"user\": 5467375659, \"tweet_id\": 6018193721, \"id\": 6122009681}, {\"time\": 1275517044, \"type\": 2, \"user\": 1305540368, \"tweet_id\": 15280521439, \"id\": 6151658638}, {\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Propagation - Cell 5F: Tree JSON → DGL graph\n\n\nimport os\nimport json\nimport dgl\nimport torch\n\nGRAPH_ROOT = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\ndef load_tree_json(path):\n    with open(path, \"r\") as f:\n        return json.load(f)\n\ndef tree_to_edges_and_types(node, edges, node_types):\n    \"\"\"\n    Recursively traverse the tree and collect:\n    - edges: (parent_id, child_id)\n    - node_types: node_id -> type (1 = source, 2 = retweet, etc.)\n    \"\"\"\n    nid = node[\"id\"]\n    ntype = node.get(\"type\", 0)\n    node_types[nid] = ntype\n\n    children = node.get(\"children\", [])\n    for child in children:\n        cid = child[\"id\"]\n        ctype = child.get(\"type\", 0)\n        node_types[cid] = ctype\n        edges.append((nid, cid))\n        tree_to_edges_and_types(child, edges, node_types)\n\ndef build_dgl_from_tree_json(path):\n    data = load_tree_json(path)\n\n    edges = []\n    node_types = {}\n\n    # Root of the propagation tree\n    tree_to_edges_and_types(data, edges, node_types)\n\n    # Collect all node IDs\n    node_ids = sorted(node_types.keys())\n    id_map = {nid: i for i, nid in enumerate(node_ids)}\n\n    # Map edges to 0..N-1\n    if len(edges) > 0:\n        src = [id_map[u] for (u, v) in edges]\n        dst = [id_map[v] for (u, v) in edges]\n    else:\n        # single-node graph with no edges\n        src, dst = [], []\n\n    g = dgl.graph((src, dst), num_nodes=len(node_ids))\n\n    # Add self-loops for stability\n    g = dgl.add_self_loop(g)\n\n    # Node features:\n    #   feature[0] = type (1,2,...) normalized\n    #   feature[1] = degree (in + out)\n    types_tensor = torch.zeros(g.num_nodes(), 1)\n    for nid, orig_id in enumerate(node_ids):\n        types_tensor[nid, 0] = float(node_types.get(orig_id, 0))\n\n    degrees = (g.in_degrees() + g.out_degrees()).float().unsqueeze(1)\n\n    # Normalize type slightly (optional)\n    feat = torch.cat([types_tensor, degrees], dim=1)  # shape [N, 2]\n    g.ndata[\"feat\"] = feat\n\n    return g\n\n# Test on a sample file \ncategory = \"gossipcop_fake\"  # you can change to 'gossipcop_real', 'politifact_fake', etc.\nfolder_path = os.path.join(GRAPH_ROOT, category)\nfiles = sorted(os.listdir(folder_path))\n\nprint(f\"Category: {category}, num files: {len(files)}\")\nsample_file = files[0]\nsample_path = os.path.join(folder_path, sample_file)\nprint(\"Sample file:\", sample_path)\n\ng = build_dgl_from_tree_json(sample_path)\n\nprint(\"\\n DGL graph built from tree JSON\")\nprint(\"Nodes:\", g.num_nodes())\nprint(\"Edges:\", g.num_edges())\nprint(\"Node feature shape:\", g.ndata[\"feat\"].shape)\nprint(\"First 5 node features:\\n\", g.ndata[\"feat\"][:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:57:49.817346Z","iopub.execute_input":"2025-11-30T20:57:49.817874Z","iopub.status.idle":"2025-11-30T20:57:49.863610Z","shell.execute_reply.started":"2025-11-30T20:57:49.817849Z","shell.execute_reply":"2025-11-30T20:57:49.863031Z"}},"outputs":[{"name":"stdout","text":"Category: gossipcop_fake, num files: 3684\nSample file: /kaggle/working/fake-news-propagation/data/nx_network_data/gossipcop_fake/gossipcop-1000240645.json\n\n DGL graph built from tree JSON\nNodes: 130\nEdges: 259\nNode feature shape: torch.Size([130, 2])\nFirst 5 node features:\n tensor([[2., 4.],\n        [2., 3.],\n        [2., 5.],\n        [2., 3.],\n        [2., 3.]])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Propagation - Cell 6: Build Graph Dataset + Loader\n\n\nimport os\nimport dgl\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nGRAPH_ROOT = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\n# Use the graph builder function from Cell 5F\n# build_dgl_from_tree_json(path)\n\nclass PropagationGraphDataset(Dataset):\n    def __init__(self, graph_root):\n        self.samples = []\n        \n        # Define label mapping\n        # fake -> 1, real -> 0\n        folder_to_label = {\n            \"gossipcop_fake\": 1,\n            \"politifact_fake\": 1,\n            \"gossipcop_real\": 0,\n            \"politifact_real\": 0,\n        }\n\n        for folder, label in folder_to_label.items():\n            folder_path = os.path.join(graph_root, folder)\n            files = os.listdir(folder_path)\n\n            for fname in files:\n                if fname.endswith(\".json\"):\n                    full_path = os.path.join(folder_path, fname)\n                    self.samples.append((full_path, label))\n\n        print(f\"Total graphs collected: {len(self.samples)}\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        g = build_dgl_from_tree_json(path)\n        return g, torch.tensor(label, dtype=torch.long)\n\n\n# Build dataset \ngraph_dataset = PropagationGraphDataset(GRAPH_ROOT)\n\n# Test a single sample\ng, label = graph_dataset[0]\nprint(\"One sample graph:\")\nprint(\"Nodes:\", g.num_nodes())\nprint(\"Edges:\", g.num_edges())\nprint(\"Label:\", label.item())\n\n#  Collate function (DGL batch graphs)\ndef collate_graphs(batch):\n    graphs, labels = zip(*batch)\n    batched_graph = dgl.batch(graphs)\n    labels = torch.stack(labels)\n    return batched_graph, labels\n\n#  DataLoader \ngraph_loader = DataLoader(\n    graph_dataset,\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_graphs\n)\n\nprint(\"\\nGraph DataLoader ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:57:58.142687Z","iopub.execute_input":"2025-11-30T20:57:58.143367Z","iopub.status.idle":"2025-11-30T20:57:58.175156Z","shell.execute_reply.started":"2025-11-30T20:57:58.143342Z","shell.execute_reply":"2025-11-30T20:57:58.174518Z"}},"outputs":[{"name":"stdout","text":"Total graphs collected: 11257\nOne sample graph:\nNodes: 5\nEdges: 9\nLabel: 1\n\nGraph DataLoader ready.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Propagation - Cell 7: GNN classifier training\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import Subset, random_split, DataLoader\nimport dgl\nimport dgl.nn.pytorch as dglnn\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score\n\n# We'll run GNN on CPU to avoid DGL/CUDA issues\ndevice = torch.device(\"cpu\")\nprint(\"Using device for GNN:\", device)\n\n# Use a subset of graphs for faster training\ntotal_graphs = len(graph_dataset)\nmax_graphs = min(2000, total_graphs)   # cap at 2000 for speed\n\nindices = torch.randperm(total_graphs)[:max_graphs]\nsubset = Subset(graph_dataset, indices)\n\ntrain_size = int(0.8 * max_graphs)\nval_size = max_graphs - train_size\n\ntrain_subset, val_subset = random_split(subset, [train_size, val_size])\n\ntrain_graph_loader = DataLoader(\n    train_subset,\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_graphs\n)\n\nval_graph_loader = DataLoader(\n    val_subset,\n    batch_size=16,\n    shuffle=False,\n    collate_fn=collate_graphs\n)\n\nprint(f\"Graphs used: {max_graphs} (train {train_size}, val {val_size})\")\n\n\n#Define GNN model\nclass GraphClassifier(nn.Module):\n    def __init__(self, in_feats=2, hidden_dim=64, num_classes=2):\n        super().__init__()\n        self.conv1 = dglnn.GraphConv(in_feats, hidden_dim)\n        self.conv2 = dglnn.GraphConv(hidden_dim, hidden_dim)\n        self.classifier = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, g):\n        # g.ndata[\"feat\"] is shape [N, in_feats]\n        h = g.ndata[\"feat\"]\n        h = self.conv1(g, h)\n        h = torch.relu(h)\n        h = self.conv2(g, h)\n        h = torch.relu(h)\n        g.ndata[\"h\"] = h\n        # Graph-level representation: mean of node embeddings\n        hg = dgl.mean_nodes(g, \"h\")\n        logits = self.classifier(hg)\n        return logits\n\n\nmodel_gnn = GraphClassifier(in_feats=2, hidden_dim=64, num_classes=2).to(device)\noptimizer = Adam(model_gnn.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\nnum_epochs_gnn = 3\n\nfor epoch in range(num_epochs_gnn):\n    print(f\"\\n===== GNN Epoch {epoch+1}/{num_epochs_gnn} =====\")\n    model_gnn.train()\n    epoch_loss = 0.0\n    step = 0\n\n    # ---- Training loop ----\n    for batched_graph, labels in tqdm(train_graph_loader):\n        batched_graph = batched_graph.to(device)\n        labels = labels.to(device)\n\n        logits = model_gnn(batched_graph)\n        loss = criterion(logits, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        step += 1\n\n        if step % 20 == 0:\n            print(f\"Step {step} - Avg loss: {epoch_loss / step:.4f}\")\n\n    print(f\"Epoch {epoch+1} finished. Avg train loss: {epoch_loss / max(step,1):.4f}\")\n\n    # ---- Validation ----\n    model_gnn.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batched_graph, labels in val_graph_loader:\n            batched_graph = batched_graph.to(device)\n            labels_np = labels.numpy()\n\n            logits = model_gnn(batched_graph)\n            preds = logits.argmax(dim=1).cpu().numpy()\n\n            all_preds.append(preds)\n            all_labels.append(labels_np)\n\n    import numpy as np\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"[GNN Epoch {epoch+1}] Validation Accuracy: {acc:.4f}\")\n\nprint(\"\\n GNN training on propagation graphs complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:58:07.117952Z","iopub.execute_input":"2025-11-30T20:58:07.118631Z","iopub.status.idle":"2025-11-30T20:58:29.459125Z","shell.execute_reply.started":"2025-11-30T20:58:07.118607Z","shell.execute_reply":"2025-11-30T20:58:29.458405Z"}},"outputs":[{"name":"stdout","text":"Using device for GNN: cpu\nGraphs used: 2000 (train 1600, val 400)\n\n===== GNN Epoch 1/3 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b5ffe96d164e53a6ba0772c3f7b423"}},"metadata":{}},{"name":"stdout","text":"Step 20 - Avg loss: 0.6805\nStep 40 - Avg loss: 0.6738\nStep 60 - Avg loss: 0.6596\nStep 80 - Avg loss: 0.6523\nStep 100 - Avg loss: 0.6461\nEpoch 1 finished. Avg train loss: 0.6461\n[GNN Epoch 1] Validation Accuracy: 0.6575\n\n===== GNN Epoch 2/3 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a4157723c834a6aa7ed775d2629a0ee"}},"metadata":{}},{"name":"stdout","text":"Step 20 - Avg loss: 0.5999\nStep 40 - Avg loss: 0.5991\nStep 60 - Avg loss: 0.6018\nStep 80 - Avg loss: 0.5867\nStep 100 - Avg loss: 0.5871\nEpoch 2 finished. Avg train loss: 0.5871\n[GNN Epoch 2] Validation Accuracy: 0.7150\n\n===== GNN Epoch 3/3 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4953b82b11b644d993cae0f1e6825803"}},"metadata":{}},{"name":"stdout","text":"Step 20 - Avg loss: 0.5589\nStep 40 - Avg loss: 0.5569\nStep 60 - Avg loss: 0.5511\nStep 80 - Avg loss: 0.5491\nStep 100 - Avg loss: 0.5542\nEpoch 3 finished. Avg train loss: 0.5542\n[GNN Epoch 3] Validation Accuracy: 0.7500\n\n GNN training on propagation graphs complete.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# ============================================\n# Multimodal - Cell 8: BERT + GNN Fusion Model\n# ============================================\n\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device for multimodal:\", device)\n\n# ---------------------------\n# Fusion Dataset\n# ---------------------------\n\nclass MultimodalDataset(torch.utils.data.Dataset):\n    def __init__(self, df_text, graph_root, tokenizer, max_len=256):\n        \"\"\"\n        df_text: dataframe with text and label_id\n        graph_root: propagation graph directory\n        \"\"\"\n        self.texts = df_text[\"text\"].tolist()\n        self.labels = df_text[\"label_id\"].tolist()\n        self.ids = df_text.get(\"id\", df_text.index).tolist()  # we will assume filename contains ID\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.graph_root = graph_root\n\n    def __len__(self):\n        return len(self.texts)\n\n    def get_graph_path(self, article_id):\n        # find matching graph file\n        for folder in os.listdir(self.graph_root):\n            folder_path = os.path.join(self.graph_root, folder)\n            if not os.path.isdir(folder_path):\n                continue\n            \n            # guess possible filenames:\n            for name in os.listdir(folder_path):\n                if article_id in name:\n                    return os.path.join(folder_path, name)\n        \n        return None  # graph not found\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = int(self.labels[idx])\n\n        enc = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n\n        # find graph file\n        article_id = str(self.ids[idx])\n        graph_path = self.get_graph_path(article_id)\n\n        if graph_path is None:\n            # fallback: return small dummy graph\n            g = dgl.graph(([], []), num_nodes=1)\n            g = dgl.add_self_loop(g)\n            g.ndata[\"feat\"] = torch.zeros(1, 2)\n        else:\n            g = build_dgl_from_tree_json(graph_path)\n\n        # remove batch dimension on BERT inputs\n        item = {\n            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n            \"graph\": g,\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }\n        return item\n\n\n# Fusion Model\n\n\nclass FusionModel(nn.Module):\n    def __init__(self, bert_name=\"distilbert-base-uncased\", graph_in=2, graph_hidden=64, graph_out=128, num_classes=2):\n        super().__init__()\n        self.text_encoder = AutoModel.from_pretrained(bert_name)\n\n        self.gnn1 = dglnn.GraphConv(graph_in, graph_hidden)\n        self.gnn2 = dglnn.GraphConv(graph_hidden, graph_out)\n\n        # DistilBERT hidden size = 768\n        self.classifier = nn.Sequential(\n            nn.Linear(768 + graph_out, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, input_ids, attention_mask, g):\n        # Text encoding\n        out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n        h_text = out.last_hidden_state[:, 0, :]     # CLS-like\n\n        # GNN encoding\n        h = g.ndata[\"feat\"]\n        h = torch.relu(self.gnn1(g, h))\n        h = torch.relu(self.gnn2(g, h))\n        g.ndata[\"h\"] = h\n        h_graph = dgl.mean_nodes(g, \"h\")\n\n        # Align batch dims\n        if h_graph.shape[0] != h_text.shape[0]:\n            h_graph = h_graph.unsqueeze(0)\n\n        # Fusion\n        fused = torch.cat([h_text, h_graph], dim=1)\n        logits = self.classifier(fused)\n        return logits.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:07:30.762778Z","iopub.execute_input":"2025-11-30T21:07:30.763101Z","iopub.status.idle":"2025-11-30T21:07:30.776150Z","shell.execute_reply.started":"2025-11-30T21:07:30.763077Z","shell.execute_reply":"2025-11-30T21:07:30.775465Z"}},"outputs":[{"name":"stdout","text":"Using device for multimodal: cuda\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"\n# Multimodal - Cell 9 (FIXED): Train FusionModel on CPU\n\n\nimport torch\nfrom torch.utils.data import DataLoader, Subset\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report\nimport numpy as np\n\n# Force CPU because DGL is CPU-only here\ndevice = torch.device(\"cpu\")\nprint(\"Using device:\", device)\n\ngraph_root = \"/kaggle/working/fake-news-propagation/data/nx_network_data\"\n\n#  Build multimodal datasets (same as before)\nmultimodal_train_ds = MultimodalDataset(train_fakenet, graph_root, tokenizer, max_len=256)\nmultimodal_val_ds   = MultimodalDataset(val_fakenet,   graph_root, tokenizer, max_len=256)\n\n# Subsample for speed\nmax_mm_train = 1500\nmax_mm_val   = 400\n\ntrain_indices = torch.randperm(len(multimodal_train_ds))[:max_mm_train]\nval_indices   = torch.randperm(len(multimodal_val_ds))[:max_mm_val]\n\ntrain_mm_subset = Subset(multimodal_train_ds, train_indices)\nval_mm_subset   = Subset(multimodal_val_ds,   val_indices)\n\nprint(\"Multimodal train samples:\", len(train_mm_subset))\nprint(\"Multimodal val samples  :\", len(val_mm_subset))\n\n\ndef collate_multimodal(batch):\n    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n    labels = torch.stack([item[\"labels\"] for item in batch])\n    graphs = [item[\"graph\"] for item in batch]\n    batched_graph = dgl.batch(graphs)  # stays on CPU\n    return input_ids, attention_mask, batched_graph, labels  # all CPU tensors\n\nmultimodal_train_loader = DataLoader(\n    train_mm_subset, batch_size=8, shuffle=True, collate_fn=collate_multimodal\n)\nmultimodal_val_loader = DataLoader(\n    val_mm_subset, batch_size=8, shuffle=False, collate_fn=collate_multimodal\n)\n\n# Init fusion model on CPU\nfusion_model = FusionModel(\n    bert_name=model_name,\n    graph_in=2,\n    graph_hidden=64,\n    graph_out=128,\n    num_classes=2\n).to(device)\n\noptimizer = torch.optim.Adam(fusion_model.parameters(), lr=1e-5)\ncriterion = torch.nn.CrossEntropyLoss()\n\nnum_epochs_fusion = 2\n\nfor epoch in range(num_epochs_fusion):\n    print(f\"\\n Fusion Epoch {epoch+1}/{num_epochs_fusion} =====\")\n    fusion_model.train()\n    epoch_loss = 0.0\n    step = 0\n\n    for input_ids, attention_mask, graphs, labels in tqdm(multimodal_train_loader):\n        # move ONLY tensors, graphs stay CPU but model is also on CPU\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        # graphs already on CPU; no .to(device) here\n\n        logits = fusion_model(input_ids, attention_mask, graphs)\n        loss = criterion(logits, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        step += 1\n\n        if step % 20 == 0:\n            print(f\"Step {step} - Avg loss: {epoch_loss / step:.4f}\")\n\n    print(f\"Epoch {epoch+1} train loss: {epoch_loss / step:.4f}\")\n\n    # Validation\n    fusion_model.eval()\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for input_ids, attention_mask, graphs, labels in multimodal_val_loader:\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels_np = labels.numpy()  # keep on CPU\n\n            logits = fusion_model(input_ids, attention_mask, graphs)\n            preds = logits.argmax(dim=1).cpu().numpy()\n\n            all_preds.append(preds)\n            all_labels.append(labels_np)\n\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"[Fusion Epoch {epoch+1}] Validation Accuracy: {acc:.4f}\")\n    print(\"Classification report:\")\n    print(classification_report(all_labels, all_preds, target_names=[\"real\", \"fake\"]))\n\nprint(\"\\nMultimodal BERT+GNN training complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:38:20.682077Z","iopub.execute_input":"2025-11-30T21:38:20.682399Z","iopub.status.idle":"2025-11-30T22:00:06.567958Z","shell.execute_reply.started":"2025-11-30T21:38:20.682374Z","shell.execute_reply":"2025-11-30T22:00:06.566929Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nMultimodal train samples: 1500\nMultimodal val samples  : 400\n\n Fusion Epoch 1/2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30d81638822a4a3f92d5abdd4e4a606c"}},"metadata":{}},{"name":"stdout","text":"Step 20 - Avg loss: 0.5785\nStep 40 - Avg loss: 0.5614\nStep 60 - Avg loss: 0.5133\nStep 80 - Avg loss: 0.4295\nStep 100 - Avg loss: 0.3693\nStep 120 - Avg loss: 0.3238\nStep 140 - Avg loss: 0.2864\nStep 160 - Avg loss: 0.2605\nStep 180 - Avg loss: 0.2350\nEpoch 1 train loss: 0.2277\n[Fusion Epoch 1] Validation Accuracy: 0.9875\nClassification report:\n              precision    recall  f1-score   support\n\n        real       1.00      0.98      0.99       306\n        fake       0.95      1.00      0.97        94\n\n    accuracy                           0.99       400\n   macro avg       0.97      0.99      0.98       400\nweighted avg       0.99      0.99      0.99       400\n\n\n Fusion Epoch 2/2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9d404647f74aa6af0612d238953287"}},"metadata":{}},{"name":"stdout","text":"Step 20 - Avg loss: 0.0325\nStep 40 - Avg loss: 0.0289\nStep 60 - Avg loss: 0.0295\nStep 80 - Avg loss: 0.0277\nStep 100 - Avg loss: 0.0303\nStep 120 - Avg loss: 0.0356\nStep 140 - Avg loss: 0.0369\nStep 160 - Avg loss: 0.0398\nStep 180 - Avg loss: 0.0367\nEpoch 2 train loss: 0.0356\n[Fusion Epoch 2] Validation Accuracy: 0.9825\nClassification report:\n              precision    recall  f1-score   support\n\n        real       1.00      0.98      0.99       306\n        fake       0.93      1.00      0.96        94\n\n    accuracy                           0.98       400\n   macro avg       0.97      0.99      0.98       400\nweighted avg       0.98      0.98      0.98       400\n\n\nMultimodal BERT+GNN training complete!\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}